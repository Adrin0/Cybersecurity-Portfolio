from general import create_dir, write_file
from domain_name import get_domain_name
from ip_address import get_ip_address
from nmap import get_nmap
from robots_txt import get_robots_txt
from whois import get_whois

ROOT_DIR = 'companies'
create_dir(ROOT_DIR)

def gather_info(name, url):

        # Ensure the URL has a protocol
    if not url.startswith("http://") and not url.startswith("https://"):
        url = "http://" + url

    domain_name = get_domain_name(url)
    print(f"Resolved domain name: {domain_name}")  # Debug print

    ip_address = get_ip_address(domain_name) # Pass only the domain name here
    
    if ip_address is None:
        print(f"Error: Could not resolve the domain name {domain_name}")
        return
    
    nmap = get_nmap('-F', ip_address)
    robots_txt = get_robots_txt(url)
    whois = get_whois(domain_name)
    create_report(name, url, domain_name, ip_address, nmap, robots_txt, whois)

def create_report(name, url, domain_name, ip_address, nmap, robots_txt, whois):
    project_dir = ROOT_DIR + '/' + name
    create_dir(project_dir)
    write_file(project_dir + '/full_url.txt', url)
    write_file(project_dir + '/domain_name.txt', domain_name)
    write_file(project_dir + '/ip_address.txt', ip_address)
    write_file(project_dir + '/nmap.txt', nmap)
    write_file(project_dir + '/robots_txt.txt', robots_txt)
    write_file(project_dir + '/whois.txt', whois)

# Run the function with an example
gather_info('google', 'google.com')